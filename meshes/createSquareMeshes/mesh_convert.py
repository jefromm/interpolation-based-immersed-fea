'''
Workflow to convert the mesh files generated by XTK from Exodus to XDMF format
run with: 
python3 mesh_convert.py --fi "xtk_temp.exo" --fo "mesh.xdmf"
'''
import meshio 
import argparse

from InterpolationBasedImmersedFEA.common import *
from InterpolationBasedImmersedFEA.profile_utils import profile_separate
from InterpolationBasedImmersedFEA.la_utils import *

import numpy as np

parser = argparse.ArgumentParser()
parser.add_argument('--fi',dest='fi',default="xtk_temp.exo",
                    help='Input mesh file')
parser.add_argument('--fo',dest='fo',default="mesh.xdmf",
                    help='Output mesh file')
parser.add_argument('--CExOps',dest='CExOps',default=False,
                    help='Convert Extraction Operators, T/F')
                    
args = parser.parse_args()
CExOps = args.CExOps
FILE_IN = args.fi
FILE_OUT = args.fo


def makeIDsConsecutive(original_cells, original_points):

    #first create maps from the old ID to new, and vis versa 
    cons2noncons = np.unique(original_cells.flatten()) #index is new ID, value is old
    noncons2cons = np.zeros(np.max(cons2noncons)+1,dtype=np.int32) - 1 # index is old ID, value is new 
    i = 0
    for nonconsID in cons2noncons:
        noncons2cons[nonconsID] = i # index is old ID, value is new 
        #print(original_points[nonconsID])
        new_pt = original_points[nonconsID].reshape(1,3)
        if i == 0:
            new_points = new_pt
        else:
            new_points = np.concatenate((new_points, new_pt), axis=0)
        i = i +1


    #manipulate array format
    row, col = np.shape(original_cells)
    cells_flat = original_cells.flatten()
    new_cells = np.zeros_like(cells_flat) - 1
    i = 0
    for ID in cells_flat:
        new_cells[i] = noncons2cons[ID]
        i = i + 1;
    #changeArr(new_cells)
    new_cells = new_cells.reshape(row, col)

    return new_cells, new_points, noncons2cons

def trimHOPoints(original_cells, original_points):
    used_IDS = np.unique(original_cells.flatten()) #index is new ID, value is old
    #check: 
    i = 0 
    for used_ID in used_IDS:
        new_pt = original_points[used_ID].reshape(1,3)
        if i == 0:
            new_points = new_pt
        else:
            new_points = np.concatenate((new_points, new_pt), axis=0)
        i = i +1

    return new_points


print(">>> Reading the mesh file...")

exo = meshio.read(FILE_IN)
print(">>> Creating material data ...")
block = 1
#Cell ID key: block 1 => mat 1, block 2 => mat 2
#XDMF files can store cell attributes
for cell in exo.cells:
    node_list = cell.data
    cell_type = cell.type
    if block == 1:
        cells = node_list
        materials = np.ones((1,len(node_list)))
        num_block_cells = len(node_list)
    else:
        cells = np.concatenate((cells, node_list))
        materials = np.concatenate((materials, block*np.ones((1,len(node_list)))),axis = 1)
    block = block+1
points = exo.points

print(">>> Making IDS consecutive")
cells, points, nodeIDmap = makeIDsConsecutive(cells, points)

#if cell_type == "triangle": - cell_type stays, no truncation
if cell_type == "tetra4":
    #3d, linear, change cell type name to xdmf format
    cell_type = "tetra"
elif cell_type == "triangle6":
    #2d, quad
    # make file with cell node data 
    print(">>> Making high order node mesh")
    node_name = "cell_nodes.csv"
    HO_cells = cells
    np.savetxt(node_name,cells,fmt="%d",delimiter=",")
    cells = np.delete(cells, [3, 4, 5], 1)
    cell_type = "triangle"
    points = trimHOPoints(cells,points)
elif cell_type == "tetra10":
    #3d, quad, change cell type name to tetra
    # make file with cell node data 
    print(">>> Making high order node mesh")
    node_name ="cell_nodes.csv"
    np.savetxt(node_name,cells,fmt="%d",delimiter=",")
    cells = np.delete(cells, [4, 5, 6, 7, 8, 9], 1)
    cell_type = "tetra"
    points = trimHOPoints(cells,points)

print(">>> Creating new mesh ...")
if cell_type == "triangle" or cell_type == "triangle6":
    print(">>> pruneing z coord")
    new_points = np.delete(points, 2, 1)
    points = new_points

mesh = meshio.Mesh(points=points,cells=[(cell_type, cells)],
    cell_data={"material":materials})

print(">>> Writing the mesh file...")
meshio.write(FILE_OUT,mesh)



if CExOps:
    print(">>> Relabeling nodeIDs in extraction operators...")
    i = 0

    fileNamesBoth = ['Global_Extraction_Operators.0.hdf5', 'Global_Extraction_Operators.1.hdf5']
    fileNames = ['Global_Extraction_Operators.1.hdf5']
    fileNames_0 = ['Global_Extraction_Operators.0.hdf5']
    
    # first, do just ex op 1, which only covers material 1 
    f = h5py.File(fileNames[0], "r")
    a_group_key = list(f.keys())[0]
    b_group_key = list(f.keys())[1]
    indices = np.array(f[a_group_key])
    weights = np.array(f[b_group_key])
    fg_dofs = indices[:,0]
    i = 0
    
    for dof in fg_dofs:
        indices[i,0] = nodeIDmap[int(dof-1)] + 1
        i = 1+i
    matData = np.concatenate((indices,weights), axis=1)
    new_ExOP ="ExOp_Cons.csv"
    np.savetxt(new_ExOP,matData,fmt="%d %d %1.16f",delimiter=",")

    ################## Also output consecutive ex ops for both extraction operators
    #print(nodeIDmap)
    count = 0
    for filename in fileNamesBoth : 
        f = h5py.File(filename, "r")
        a_group_key = list(f.keys())[0]
        b_group_key = list(f.keys())[1]
        if count == 0:
            indices = np.array(f[a_group_key])
            weights = np.array(f[b_group_key])
        else:
            indices = np.concatenate((indices, np.array(f[a_group_key])), axis=0)
            weights = np.concatenate((weights, np.array(f[b_group_key])), axis=0)
        count = count + 1
    fg_dofs = indices[:,0]
    i = 0
    for dof in fg_dofs:
        indices[i,0] = nodeIDmap[int(dof-1)] + 1
        i = 1+i
    matData = np.concatenate((indices,weights), axis=1)
    
    new_ExOP ="ExOp_Cons_Both.csv"
    np.savetxt(new_ExOP,matData,fmt="%d %d %1.16f",delimiter=",")
    ################## Also output consecutive ex ops for only the outside

    i = 0 
    f = h5py.File(fileNames_0[0], "r")
    a_group_key = list(f.keys())[0]
    b_group_key = list(f.keys())[1]
    indices = np.array(f[a_group_key])
    weights = np.array(f[b_group_key])
    
    fg_dofs = indices[:,0]
    i = 0
    for dof in fg_dofs:
        indices[i,0] = nodeIDmap[int(dof-1)] + 1
        i = 1+i
    matData = np.concatenate((indices,weights), axis=1)    
    new_ExOP ="ExOp_Cons_zero.csv"
    np.savetxt(new_ExOP,matData,fmt="%d %d %1.16f",delimiter=",")